{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "<ol>\n",
    "    <li> Create a point cloud representation\n",
    "    <li> Create a graph representation from the given point cloud\n",
    "    <li> Train a GNN model from Quark/Gluon classification\n",
    "</ol>\n",
    "\n",
    "### Issue\n",
    "<ul>\n",
    "    <li> A point cloud is nothing but a 3d representation of a point but the give data only<br> \n",
    "    contains 2d data i.e x, y coordinate and value of the particular channel at that point. <br>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import h5py\n",
    "import torch\n",
    "from torch_geometric.data import Dataset as PygDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from multiprocessing import Pool\n",
    "from torch_geometric.nn import GATConv, Linear, TopKPooling, global_max_pool as gmp, global_mean_pool as gap\n",
    "from torchvision import transforms\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm import tqdm\n",
    "cpu_count = mp.cpu_count()\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_dataset(raw_path, processed_path, subset_len = 6000, starter = 0):\n",
    "    with h5py.File(raw_path, 'r') as f, h5py.File(processed_path, 'w') as p:\n",
    "        keys = list(f.keys())\n",
    "        total_events = f[keys[1]].shape[0]\n",
    "        for key in keys:\n",
    "            shape = (subset_len,)\n",
    "            if len(f[key].shape) > 1:\n",
    "                shape = (subset_len, 125, 125, 3)\n",
    "            p.create_dataset(key, shape=shape)\n",
    "        quark_count = 0\n",
    "        gluon_count = 0\n",
    "        idx = 0\n",
    "        for i in range(starter, starter + subset_len):\n",
    "            if quark_count < subset_len // 2:\n",
    "                for key in keys:\n",
    "                    p[key][idx] = f[key][i]\n",
    "                quark_count += 1\n",
    "                idx += 1\n",
    "            elif gluon_count < subset_len // 2:\n",
    "                for key in keys:\n",
    "                    p[key][idx] = f[key][i]\n",
    "                gluon_count += 1\n",
    "                idx+=1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset is too large so instead a small subset is <br>\n",
    "is used as a POC for Quark/Gluon classification using Graph Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../Data/hdf5/processed/train.hdf5\"\n",
    "val_path = \"../Data/hdf5/processed/val.hdf5\"\n",
    "test_path = \"../Data/hdf5/processed/test.hdf5\"\n",
    "quark_gluon_path = \"../Data/hdf5/processed/quark-gluon-dataset.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dataset(quark_gluon_path, train_path, 600)\n",
    "subset_dataset(quark_gluon_path, val_path, 120, 600)\n",
    "subset_dataset(quark_gluon_path, test_path, 120, 720)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a graph representation we treat all non-zero positions of any channel as nodes <br>\n",
    "and these non zero points will have the features as the channel values i.e [ecal, hcal, tracks] <br>\n",
    "at that particular position. Edges are formed between nodes by calculating the k-nearest <br>\n",
    "neighbours using euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pillow(x):\n",
    "    return x.transpose((2,1,0))\n",
    "def get_k_nearest(indices, k = 10):\n",
    "    edges = None\n",
    "    for i in range(indices.shape[0]):\n",
    "        k_nearest = np.sum((indices - indices[i])**2, axis=1).argsort()\n",
    "        k_nearest_edges = np.array([[i, j] for j in k_nearest[1:k]])\n",
    "        if edges is None:\n",
    "            edges = k_nearest_edges\n",
    "        else:\n",
    "            edges = np.vstack((edges, k_nearest_edges))\n",
    "    return edges\n",
    "def create_graph(idx,quark_gluon_path ,outpath ):\n",
    "    data = Data()\n",
    "    with h5py.File(quark_gluon_path, 'r') as f:\n",
    "        y = f['y'][idx]\n",
    "        x = f['X_jets'][idx]\n",
    "        non_zero_indices = np.argwhere(np.sum(x, axis=2))\n",
    "        non_zero_fetures = x[non_zero_indices[:, 0], non_zero_indices[:, 1]]\n",
    "        data.x = torch.from_numpy(non_zero_fetures)\n",
    "        edges = get_k_nearest(non_zero_indices)\n",
    "        data.edge_index = torch.from_numpy(edges).t().contiguous().to(torch.int64)\n",
    "        data.y = torch.from_numpy(np.asarray([y]))\n",
    "        data.pos = torch.from_numpy(non_zero_indices)\n",
    "        torch.save(data, osp.join(outpath, f\"{idx}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapher(root_dir = \"../Data/hdf5/processed\"):\n",
    "    files = [\"train.hdf5\", \"val.hdf5\", \"test.hdf5\"]\n",
    "    for file in files:\n",
    "        path = osp.join(root_dir , file)\n",
    "        with h5py.File(path, 'r') as f:\n",
    "            event_count = len(f[\"X_jets\"])\n",
    "        data = file.split(\".\")[0]\n",
    "        for i in range(event_count):\n",
    "            create_graph(i, path , \"../Data/Graphs/{}/raw\".format(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuarkGluonGraphs(PygDataset):\n",
    "    def __init__(self, root = None, transform = None, pre_transform = None, pre_filter = None, log = True):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter, log)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return os.listdir(osp.join(self.root, \"raw\"))\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return os.listdir(osp.join(self.root, \"raw\"))\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        for raw_path in self.raw_file_names:\n",
    "            data = torch.load(osp.join(self.raw_dir, raw_path))\n",
    "            data.y = data.y.to(torch.int64)\n",
    "            torch.save(data, osp.join(self.processed_dir, raw_path))\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f\"{idx}.pt\"))\n",
    "        if self.transform is not None:\n",
    "            data.x = self.transform(data.x)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = None\n",
    "train_data = QuarkGluonGraphs(\"../Data/Graphs/train/\", transform=transform)\n",
    "val_data = QuarkGluonGraphs(\"../Data/Graphs/val/\", transform=transform)\n",
    "test_data = QuarkGluonGraphs(\"../Data/Graphs/test/\", transform=transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GCN](https://github.com/deepfindr/gnn-project) model in the given github repository is used as a base to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super().__init__()\n",
    "        num_classes = 2\n",
    "        embedding_size = 256\n",
    "\n",
    "        # GNN Layers\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "        self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "        # Linear Layers\n",
    "        self.linear1 = Linear(embedding_size*2, embedding_size)\n",
    "        self.linear2 = Linear(embedding_size, num_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim = -1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # first block\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.head_transform1(x)\n",
    "\n",
    "        x, edge_index, _, batch_index, _, _ = self.pool1(x, edge_index, None, batch_index) \n",
    "        x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # second block\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.head_transform2(x)\n",
    "\n",
    "        x, edge_index, _, batch_index, _, _ = self.pool2(x, edge_index, None, batch_index) \n",
    "        x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Third block\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.head_transform3(x)\n",
    "\n",
    "        x, edge_index, _, batch_index, _, _ = self.pool3(x, edge_index, None, batch_index) \n",
    "        x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # concat pooled vectors\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        # output block\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(feature_size=train_data[0].x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GATConv(3, 256, heads=3)\n",
       "  (head_transform1): Linear(768, 256, bias=True)\n",
       "  (pool1): TopKPooling(256, ratio=0.8, multiplier=1.0)\n",
       "  (conv2): GATConv(256, 256, heads=3)\n",
       "  (head_transform2): Linear(768, 256, bias=True)\n",
       "  (pool2): TopKPooling(256, ratio=0.5, multiplier=1.0)\n",
       "  (conv3): GATConv(256, 256, heads=3)\n",
       "  (head_transform3): Linear(768, 256, bias=True)\n",
       "  (pool3): TopKPooling(256, ratio=0.2, multiplier=1.0)\n",
       "  (linear1): Linear(512, 256, bias=True)\n",
       "  (linear2): Linear(256, 2, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()#(weight=weights)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GRAPHS_PER_BATCH = 8\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True\n",
    "                          )\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(\"binary\", num_classes=2)\n",
    "precision = Precision(\"binary\", num_classes=2)\n",
    "recall = Recall(\"binary\", num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, train_loader, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for _, batch in enumerate((train_loader)):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # passing the node features and the connection info\n",
    "        pred = model(batch.x,\n",
    "                     batch.edge_index.to(torch.int64),\n",
    "                     batch.batch\n",
    "                     )\n",
    "        # Calculate the loss and the gradient\n",
    "        # print(pred.shape)\n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y.float()))\n",
    "        loss.backward()\n",
    "        # Update using the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    return loss\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        # batch.to(device)\n",
    "        batch.edge_index = batch.edge_index.to(torch.int64)  \n",
    "        pred = model(batch.x, \n",
    "                        batch.edge_index, \n",
    "                        batch.batch) \n",
    "        pred_ = torch.argmax(pred, dim = 1)\n",
    "        y = torch.argmax(batch.y, dim  = 1)\n",
    "        # print(pred.shape, pred_.shape, y.shape)\n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y.float()))\n",
    "\n",
    "        prec = precision(pred_, y)\n",
    "        rec = recall(pred_, y)\n",
    "        acc = accuracy(pred_, y)\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(pred_)\n",
    "        all_labels.append(y)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    # print(all_preds.shape, all_labels.shape)\n",
    "    prec = precision(all_preds, all_labels)\n",
    "    # print(all_preds)\n",
    "    # print(all_labels)\n",
    "    rec = recall(all_preds, all_labels)\n",
    "    acc = accuracy(all_preds, all_labels)\n",
    "    # print(all_preds_raw[0][:10])\n",
    "    # print(all_preds[:10])\n",
    "    # print(all_labels[:10])\n",
    "    return running_loss, prec, rec, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 | training loss 0.835361897945404\n",
      " Epoch 0 | testing loss 124.92844700813293 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 1 | training loss 0.8361220359802246\n",
      " Epoch 1 | testing loss 125.12552988529205 | precision 0.0 | recall 0.0 | accuracy 0.5133333206176758\n",
      " Epoch 2 | training loss 0.8330801725387573\n",
      " Epoch 2 | testing loss 124.88511437177658 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 3 | training loss 0.8235042095184326\n",
      " Epoch 3 | testing loss 125.25484645366669 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 4 | training loss 0.83642578125\n",
      " Epoch 4 | testing loss 124.90925747156143 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 5 | training loss 0.8318431377410889\n",
      " Epoch 5 | testing loss 124.88898611068726 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 6 | training loss 0.8323637247085571\n",
      " Epoch 6 | testing loss 124.87893605232239 | precision 0.0 | recall 0.0 | accuracy 0.5133333206176758\n",
      " Epoch 7 | training loss 0.8286725282669067\n",
      " Epoch 7 | testing loss 124.84818017482758 | precision 0.0 | recall 0.0 | accuracy 0.5133333206176758\n",
      " Epoch 8 | training loss 0.8458583354949951\n",
      " Epoch 8 | testing loss 125.36048144102097 | precision 0.4866666793823242 | recall 1.0 | accuracy 0.4866666793823242\n",
      " Epoch 9 | training loss 0.824140191078186\n",
      " Epoch 9 | testing loss 124.91393315792084 | precision 0.0 | recall 0.0 | accuracy 0.5133333206176758\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = train(epoch, model, train_loader, loss_fn)\n",
    "    running_loss = running_loss.detach().cpu().numpy()\n",
    "    print(\" Epoch {} | training loss {}\".format(epoch, running_loss))\n",
    "    scheduler.step()\n",
    "    with torch.no_grad():\n",
    "        running_loss, prec, rec, acc = test(epoch, model, test_loader, loss_fn)\n",
    "    print(\" Epoch {} | testing loss {} | precision {} | recall {} | accuracy {}\".format(epoch, running_loss, prec, rec, acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given GCN model uses node features {ecal, hcal, tracks} and non-weighted edges for the given classification. <br>\n",
    "Possible improvements:\n",
    "<ul>\n",
    "    <li> Utilise edge attribute as distance between the nodes\n",
    "    <li> Utilise positional(geometric) information.\n",
    "    <li> Try and check different pooling layers and select the best for our use case.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7e9d0b6ec238a7d2d97d894925170bb7e5915a26ee8ae88ee5a8209d1d0e607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
